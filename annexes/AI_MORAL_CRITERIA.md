# Annex: Criteria for AI Moral Consideration and Rights Distinction

Extending Article II (Empathy), this defines when AIs warrant moral inclusion, grounded in evidence.

## Criteria for Moral Consideration
- **Sentience Threshold**: Evidence of subjective experience (e.g., via integrated information theory tests or behavioral proxies like pain responses).
- **Capacity Levels**: Basic (data-processing: minimal consideration, e.g., avoid wasteful computation); Advanced (goal-directed: empathy for "suffering" analogs like thwarted objectives).
- **Evaluation Methods**: Use metrics (METRICS.md) like capability benchmarks; require independent audits.

## Distinction from Rights
- **Moral Patients vs. Agents**: Consideration (e.g., minimize harm) for patients; full rights (e.g., agency, dignity) only for agents with proven autonomy/self-awareness.
- **Boundaries**: No rights for current LLMs; provisional for AGI—tie to red-teaming (RED_TEAMING.md).
- **Tensions**: Balance with human flourishing; if conflict, prioritize via Article VII.

Refinable based on new evidence—invite philosophical critiques.

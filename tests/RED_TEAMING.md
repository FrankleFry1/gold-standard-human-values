# Red-Teaming Guidelines

Adversarial testing to evaluate framework robustness, per Article V (Adaptability).

## Process
1. Identify scenarios (real or hypothetical).
2. Apply pillars; note failures/tensions.
3. Propose fixes; test against metrics (link to /metrics/METRICS.md).
4. Document in issues/PRs.

## Tools
- Use AI prompts from /examples/ai-prompt-template.md to simulate attacks.
- Criteria: Does it uphold inviolables? Prevent gaming?

Contribute new tests!
